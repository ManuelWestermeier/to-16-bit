<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Video -> AVF1 (ESP) Converter</title>
  <style>body{font-family:sans-serif;padding:12px;max-width:900px} label{margin-right:12px}</style>
</head>
<body>
<h2>Video → AVF1 Converter (RGB565 + 8-bit PCM audio)</h2>
<p>Select a video file and press Convert. Output is an <code>.avf</code> binary ready for the ESP player.</p>

<input id="file" type="file" accept="video/*">
<br><br>
<label>Width <input id="width" type="number" value="160"></label>
<label>Height <input id="height" type="number" value="120"></label>
<label>FPS <input id="fps" type="number" value="20" step="1"></label>
<br>
<label>Audio sample rate <input id="asr" type="number" value="22050"></label>
<label>Audio channels <select id="ach"><option>1</option><option selected>2</option></select></label>
<br><br>
<button id="convert">Convert</button>
<br><br>
<a id="dl" style="display:none">Download .avf</a>
<progress id="prog" value="0" max="1" style="width:80%"></progress>
<pre id="log" style="height:140px;overflow:auto;border:1px solid #ddd;padding:6px"></pre>

<video id="v" style="display:none"></video>
<canvas id="c" style="display:none"></canvas>

<script>
/* Full AVF1 converter
   - Produces file layout exactly matching the ESP player expectations:
     Header(12), optional audioHdr(10), framesCount(4), audioBytes, frames...
*/

// --- helpers to write LE numbers into byte array
function writeLE32(arr, v){ arr.push(v & 0xFF, (v>>8)&0xFF, (v>>16)&0xFF, (v>>24)&0xFF); }
function writeLE16(arr, v){ arr.push(v & 0xFF, (v>>8)&0xFF); }

// --- PackBits-like RLE used in player (compatible)
function packScanline565Bytes(scanlineBytes, widthPixels) {
  // scanlineBytes: Uint8Array length == width*2 (hi,lo per pixel)
  const out = [];
  function readPixel(idx) { return (scanlineBytes[idx*2] << 8) | scanlineBytes[idx*2+1]; }
  let i = 0;
  while (i < widthPixels) {
    // find run length of identical pixels
    let run = 1;
    while (i + run < widthPixels && readPixel(i+run) === readPixel(i) && run < 128) run++;
    if (run >= 3) {
      // repeat run: header = -(run-1) signed
      out.push((256 + (-(run-1))) & 0xFF);
      const p = readPixel(i);
      out.push((p>>8)&0xFF, p&0xFF);
      i += run;
    } else {
      // literal run: collect until next run >=3 or up to 128
      const start = i;
      let lit = 0;
      while (i < widthPixels && lit < 128) {
        // lookahead for run >=3
        let look = 1;
        while (i + look < widthPixels && readPixel(i+look) === readPixel(i+look-1)) look++;
        if (look >= 3) break;
        i++; lit++;
      }
      out.push((lit-1) & 0xFF); // header
      for (let k=0;k<lit;k++){
        const p = readPixel(start + k);
        out.push((p>>8)&0xFF, p&0xFF);
      }
    }
  }
  return new Uint8Array(out);
}

// Convert an ImageData scanline into RGB565 hi/lo bytes (big-endian per pixel)
function rgbaToRgb565Bytes(imgdata, y, width) {
  const out = new Uint8Array(width*2);
  const base = y * width * 4;
  for (let x=0;x<width;x++){
    const r = imgdata[base + x*4 + 0];
    const g = imgdata[base + x*4 + 1];
    const b = imgdata[base + x*4 + 2];
    const c565 = ((r & 0xF8) << 8) | ((g & 0xFC) << 3) | (b >> 3);
    out[x*2] = (c565 >> 8) & 0xFF;
    out[x*2+1] = c565 & 0xFF;
  }
  return out;
}

// Decode audio via WebAudio to Int16Array interleaved
async function decodeToInt16Interleaved(file, targetRate, targetChannels) {
  // decode full audio track
  const arrayBuffer = await file.arrayBuffer();
  const ac = new (window.OfflineAudioContext || window.AudioContext)({length:1, sampleRate: 44100}).constructor; // just to access constructor
  const audioCtx = new (window.AudioContext || window.webkitAudioContext)(); // runtime decoder
  const decoded = await audioCtx.decodeAudioData(arrayBuffer.slice(0));
  // now resample/convert to requested rate and channel layout (simple linear resample)
  const srcRate = decoded.sampleRate;
  const duration = decoded.duration;
  const targetLen = Math.floor(duration * targetRate + 0.5);
  const channelData = [];
  for (let ch=0; ch<decoded.numberOfChannels; ch++) channelData.push(decoded.getChannelData(ch));
  const out = new Int16Array(targetLen * targetChannels);
  for (let i=0;i<targetLen;i++){
    const t = i / targetRate;
    const srcPos = t * srcRate;
    const i0 = Math.floor(srcPos);
    const frac = srcPos - i0;
    for (let ch=0; ch<targetChannels; ch++){
      let sample = 0;
      if (decoded.numberOfChannels === 1) {
        const c = channelData[0];
        const s0 = (i0 < c.length) ? c[i0] : 0;
        const s1 = (i0+1 < c.length) ? c[i0+1] : 0;
        sample = s0*(1-frac) + s1*frac;
      } else {
        // map or mix channels: for ch 0->src0, 1->src1 if available, else mix
        if (ch < decoded.numberOfChannels) {
          const c = channelData[ch];
          const s0 = (i0 < c.length) ? c[i0] : 0;
          const s1 = (i0+1 < c.length) ? c[i0+1] : 0;
          sample = s0*(1-frac) + s1*frac;
        } else {
          // fallback: mix all channels
          let s = 0;
          for (let sc=0; sc<decoded.numberOfChannels; sc++){
            const c = channelData[sc];
            const s0 = (i0 < c.length) ? c[i0] : 0;
            const s1 = (i0+1 < c.length) ? c[i0+1] : 0;
            s += s0*(1-frac) + s1*frac;
          }
          sample = s / decoded.numberOfChannels;
        }
      }
      // float -> int16
      let val = Math.max(-1, Math.min(1, sample)) * 32767;
      out[i*targetChannels + ch] = (val|0);
    }
  }
  if (audioCtx.close) audioCtx.close();
  return out;
}

// Convert interleaved Int16Array -> unsigned 8-bit mono (0..255)
function int16InterleavedToMonoU8(int16Arr, channels) {
  const samples = Math.floor(int16Arr.length / channels);
  const out = new Uint8Array(samples);
  for (let i=0;i<samples;i++){
    let sum = 0;
    for (let c=0;c<channels;c++) sum += int16Arr[i*channels + c];
    const avg = Math.round(sum / channels);
    out[i] = ((avg + 32768) >> 8) & 0xFF;
  }
  return out;
}

// Logging helper
function log(s){ const p=document.getElementById('log'); p.textContent += s+"\n"; p.scrollTop = p.scrollHeight; }

document.getElementById('convert').onclick = async () => {
  const f = document.getElementById('file').files[0];
  if (!f) { alert('pick a file'); return; }
  const width = parseInt(document.getElementById('width').value,10) || 160;
  const height = parseInt(document.getElementById('height').value,10) || 120;
  const fps = parseInt(document.getElementById('fps').value,10) || 20;
  const asr = parseInt(document.getElementById('asr').value,10) || 22050;
  const ach = parseInt(document.getElementById('ach').value,10) || 2;

  const video = document.getElementById('v');
  const canvas = document.getElementById('c');
  canvas.width = width; canvas.height = height;
  const ctx = canvas.getContext('2d');

  log("Loading video...");
  video.src = URL.createObjectURL(f);
  await new Promise((res,rej)=> {
    video.onloadedmetadata = ()=>res();
    video.onerror = (e)=>rej(e);
  });
  const duration = video.duration;
  const framesCount = Math.max(1, Math.floor(duration * fps));
  document.getElementById('prog').max = framesCount;
  document.getElementById('prog').value = 0;
  log(`Video duration=${duration.toFixed(2)}s frames=${framesCount}`);

  log("Decoding audio to Int16 interleaved...");
  const audioPCM = await decodeToInt16Interleaved(f, asr, ach);
  log(`Decoded audio -> ${audioPCM.length} int16 samples (interleaved)`);

  log("Converting audio -> unsigned 8-bit mono...");
  const audioU8 = int16InterleavedToMonoU8(audioPCM, ach);
  log(`Audio bytes (mono u8) = ${audioU8.length}`);

  // prepare output bytes
  const out = [];

  // AVF1 header (12 bytes)
  out.push('A'.charCodeAt(0),'V'.charCodeAt(0),'F'.charCodeAt(0),'1'.charCodeAt(0));
  out.push(1); // version
  writeLE16(out, width);
  writeLE16(out, height);
  out.push(fps & 0xFF);
  const flags = (1<<0) | (1<<1); // video + audio
  out.push(flags);
  out.push(0); // reserved to fill 12 bytes total

  // audioHdr: sampleRate (4), audioBits (1)=8, audioChannels (1)=1, audioBytes (4)
  writeLE32(out, asr);
  out.push(8 & 0xFF); // audioBits 8
  out.push(1 & 0xFF); // audioChannels 1 (mono)
  const audioBytes = audioU8.length;
  writeLE32(out, audioBytes);

  // framesCount (4) -- note: player reads framesCount immediately after audio header
  writeLE32(out, framesCount);

  // append audioBytes (raw u8 PCM)
  for (let i=0;i<audioU8.length;i++) out.push(audioU8[i]);

  // Now iterate frames, capture image, compress per scanline and append [frameSize][frameBytes]
  log("Rendering frames and compressing... this may take a while.");
  for (let frame=0; frame<framesCount; frame++){
    const t = Math.min(duration, (frame + 0.0001) / fps);
    video.currentTime = t;
    await new Promise(resolve => video.onseeked = resolve);
    ctx.drawImage(video, 0, 0, width, height);
    const img = ctx.getImageData(0,0,width,height);
    // collect compressed bytes per frame by concatenating scanline compressed arrays
    const frameBytes = [];
    for (let y=0;y<height;y++){
      const scan = rgbaToRgb565Bytes(img.data, y, width);
      const cscan = packScanline565Bytes(scan, width);
      for (let b=0;b<cscan.length;b++) frameBytes.push(cscan[b]);
    }
    // write frame length and data
    writeLE32(out, frameBytes.length);
    for (let b=0;b<frameBytes.length;b++) out.push(frameBytes[b]);

    document.getElementById('prog').value = frame+1;
    if ((frame & 15) === 0) log(`frame ${frame+1}/${framesCount} compressed, size=${frameBytes.length}`);
    // small pause for UI responsiveness
    await new Promise(r=>setTimeout(r,0));
  }

  // done -> create blob and download link
  const blob = new Blob([new Uint8Array(out)], {type: 'application/octet-stream'});
  const a = document.getElementById('dl');
  a.style.display = 'inline';
  a.href = URL.createObjectURL(blob);
  a.download = `${f.name.replace(/\.[^/.]+$/,"")}.avf`;
  a.textContent = `Download .avf (${out.length} bytes)`;
  log(`Done. Generated ${out.length} bytes. Click the link to download.`);
  alert('Conversion complete — file ready for download.');
};
</script>
</body>
</html>
